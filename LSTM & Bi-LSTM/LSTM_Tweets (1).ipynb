{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IgRqKQvaQhGL"
      },
      "outputs": [],
      "source": [
        "# Suppress TensorFlow logs for cleaner output & ignore warnings\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import all the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Bidirectional, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca8b_ghQWesS"
      },
      "source": [
        "1. LSTM implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cudmgW4tXb6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448f51cf-5e1b-4e59-c87b-f9ac804072e1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /kaggle/working/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 346ms/step - accuracy: 0.6888 - loss: 0.6295 - val_accuracy: 0.7097 - val_loss: 0.6026\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 338ms/step - accuracy: 0.7045 - loss: 0.6095 - val_accuracy: 0.7097 - val_loss: 0.6026\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 344ms/step - accuracy: 0.7174 - loss: 0.5972 - val_accuracy: 0.7097 - val_loss: 0.6028\n",
            "Epoch 4/10\n",
            "\u001b[1m 52/625\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07\u001b[0m 327ms/step - accuracy: 0.7399 - loss: 0.5810"
          ]
        }
      ],
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords', download_dir='/kaggle/working/nltk_data')\n",
        "nltk.data.path.append('/kaggle/working/nltk_data')\n",
        "english_stops = set(stopwords.words('english'))\n",
        "\n",
        "# Load dataset\n",
        "train_data = pd.read_csv('phm_train.csv')  # Update path\n",
        "test_data = pd.read_csv('phm_test.csv')    # Update path\n",
        "\n",
        "# Preprocessing function\n",
        "def load_dataset(data):\n",
        "    x_data = data['tweet']\n",
        "    y_data = data['label']\n",
        "\n",
        "    # Remove HTML tags and non-alphabet characters\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex=True)\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex=True)\n",
        "\n",
        "    # Remove stopwords and convert to lowercase\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review.split() if w.lower() not in english_stops])\n",
        "\n",
        "    # Encode sentiment labels\n",
        "    # y_data = y_data.replace('positive', 1)\n",
        "    # y_data = y_data.replace('negative', 0).infer_objects(copy=False)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_train, y_train = load_dataset(train_data)\n",
        "x_test, y_test = load_dataset(test_data)\n",
        "\n",
        "# Convert Tokens to Text Strings\n",
        "x_train = x_train.apply(lambda x: ' '.join(x))\n",
        "x_test = x_test.apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=250, padding='post', truncating='post')\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=250, padding='post', truncating='post')\n",
        "\n",
        "# Define the LSTM model\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(input_dim=10000, output_dim=64))\n",
        "LSTM_model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3))\n",
        "LSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile LSTM_model\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM_model\n",
        "LSTM_model.fit(x_train_pad, y_train, epochs=10, batch_size=16, validation_data=(x_test_pad, y_test))\n",
        "\n",
        "# Evaluate on test data\n",
        "loss, accuracy = LSTM_model.evaluate(x_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "y_pred_probs = LSTM_model.predict(x_test_pad)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)  # Convert probabilities to binary labels\n",
        "print()\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print()\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x2a3ddUoweiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit histories\n",
        "history_lstm = LSTM_model"
      ],
      "metadata": {
        "id": "DWRP8MmuJeDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4grKSIDDEE"
      },
      "source": [
        "2. Bi-LSTM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXi7y2iEGWqx"
      },
      "outputs": [],
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords', download_dir='/kaggle/working/nltk_data')\n",
        "nltk.data.path.append('/kaggle/working/nltk_data')\n",
        "english_stops = set(stopwords.words('english'))\n",
        "\n",
        "# Load dataset\n",
        "train_data = pd.read_csv('phm_train.csv')  # Update path\n",
        "test_data = pd.read_csv('phm_test.csv')    # Update path\n",
        "\n",
        "# Preprocessing function\n",
        "def load_dataset(data):\n",
        "    x_data = data['tweet']\n",
        "    y_data = data['label']\n",
        "\n",
        "    # Remove HTML tags and non-alphabet characters\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex=True)\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex=True)\n",
        "\n",
        "    # Remove stopwords and convert to lowercase\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review.split() if w.lower() not in english_stops])\n",
        "\n",
        "    # Encode sentiment labels\n",
        "    # y_data = y_data.replace('positive', 1)\n",
        "    # y_data = y_data.replace('negative', 0).infer_objects(copy=False)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_train, y_train = load_dataset(train_data)\n",
        "x_test, y_test = load_dataset(test_data)\n",
        "\n",
        "# Convert Tokens to Text Strings\n",
        "x_train = x_train.apply(lambda x: ' '.join(x))\n",
        "x_test = x_test.apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=200, padding='post', truncating='post')\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=200, padding='post', truncating='post')\n",
        "\n",
        "# Define the Bi-LSTM model\n",
        "BILSTM_model = Sequential()\n",
        "BILSTM_model.add(Embedding(input_dim=10000, output_dim=64))  # Increased embedding size\n",
        "BILSTM_model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Return full sequence\n",
        "BILSTM_model.add(Dropout(0.5))\n",
        "BILSTM_model.add(Bidirectional(LSTM(32)))\n",
        "BILSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile BILSTM_model\n",
        "BILSTM_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "# Train the BILSTM_model\n",
        "BILSTM_model.fit(x_train_pad, y_train, epochs=10, batch_size=128, validation_data=(x_test_pad, y_test))\n",
        "\n",
        "# Evaluate on test data\n",
        "loss, accuracy = BILSTM_model.evaluate(x_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict & confusion matrix\n",
        "y_pred_prob = BILSTM_model.predict(x_test_pad)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "print()\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "print()\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7QYOMkkIw2Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit histories\n",
        "history_bilstm = BILSTM_model"
      ],
      "metadata": {
        "id": "liCEtrfBJjVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Comparison"
      ],
      "metadata": {
        "id": "s-HlS2t9JFGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual history variable names if different\n",
        "def plot_accuracy(history_lstm, history_bilstm):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot LSTM accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history_lstm.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history_lstm.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('LSTM Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Bi-LSTM accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history_bilstm.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history_bilstm.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Bi-LSTM Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "F9b_6fFUJD4u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}